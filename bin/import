#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
import getopt
import logging
from common import constants as constant
from DBImportOperation import import_operations
from DBImportOperation import etl_operations

def printHelp():
	print ("Options:")
	print ("  --help             Show this help message and exit")
	print ("  -v, --debug        Turn on extensive debug output. This will print passwords in cleartext, so use with caution")
	print ("  -V, --version      Displays the version of DBImport")
	print ("  --skipSqoop        Dont run the sqoop command. Useful when the Parquet files are correct and you need to recreate Hive tables")
	print ("  --ignoreTime       Ignores the start and stop time for the table. Will run outside that window regardless")
	print ("  --resetStage       Starts from the beginning regardless of previous problems")
	print ("  -h [Hive Database], --Hive_DB=[Hive Database]")
	print ("                     Hive database")
	print ("  -t [Hive Table], --Hive_Table=[Hive Table]")
	print ("                     Hive table")
	print ("  -I, -1             Only run functions in Import Phase. ")
	print ("  -C                 Only run functions in Copy Phase. ")
	print ("  -E, -2             Only run functions in ETL Phase.")
	print ("  -f [Function], --function=[Function]")
	print ("                     Only run the specified function. This is used for debugging and when migrating from")
	print ("                     bash based DBImport scripts. Using a function ignore what ever stage the import is in.")
	print ("                     Use with caution!")
	print ("                     Valid function options are:")
	print ("                     - getSourceTableSchema")
	print ("                     - sqoop")
	print ("                     - createImportTable")
	print ("                     - getSourceTableRowCount")
	print ("                     - getImportTableRowCount")
	print ("                     - getTargetTableRowCount")
	print ("                     - createTargetTable")
	print ("                     - createHistoryTable")
	print ("                     - createDeleteTable")
	print ("                     - removeHiveLocks")
	print ("                     - truncateTargetTable")
	print ("                     - loadDataFromImportTable")
	print ("                     - mergeTable")
	print ("                     - createStatistics")
	sys.exit(1)
	
def printBox(messageList):
	# This code is not completed. It was a way to easily create the Ascii boxes used in the import, but we are still using hard-coded boxes. One day.....
	if type(messageList) is not list:
		messageList = [messageList]

	startLine = ""
	stopLine = ""
	maxLength = 0
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)

	for i in range(maxLength):
		startLine += "_"
		stopLine += "_"

	print(startLine)
	for message in messageList:
		if len(message) > maxLength:
			maxLength = len(message)
	print(stopLine)

def main(argv):

	try:
		opts, args = getopt.getopt(argv, "vVICE12f:h:t:", ["version", "help", "function=", "Hive_DB=", "Hive_Table=", "debug", "skipSqoop", "ignoreTime", "resetStage"])
	except getopt.GetoptError:
		printHelp()

	version = "0.10"
	Hive_DB = None
	Hive_Table = None
	runOnlyFunction = None
	loggingLevel = logging.INFO
	skipSqoop = False
	runImportPhase = False
	runCopyPhase = False
	runETLPhase = False
	displayVersion = False
	ignoreTime = False
	resetStage = False

	if  len(opts) == 0:
		printHelp()

	for opt, arg in opts:
		if opt in ("-h", "--Hive_DB"):
			Hive_DB = arg
		elif opt in ("-t", "--Hive_Table"):
			Hive_Table = arg
		elif opt in ("-v", "--debug"):
			loggingLevel = logging.DEBUG
		elif opt in ("-V", "--version"):
			displayVersion = True
		elif opt == "--skipSqoop":
			skipSqoop = True
		elif opt == "--resetStage":
			resetStage = True
		elif opt == "--ignoreTime":
			ignoreTime = True
		elif opt in ("-f", "--function"):
			runOnlyFunction = arg
		elif opt == "--help":
			printHelp()
		elif opt == "-1":
			runImportPhase = True
		elif opt == "-2":
			runETLPhase = True
		elif opt == "-I":
			runImportPhase = True
		elif opt == "-C":
			runCopyPhase = True
		elif opt == "-E":
			runETLPhase = True

	if displayVersion == True:
		print("DBImport version: %s"%(constant.VERSION))
		sys.exit(0)

	if Hive_DB == None or Hive_Table == None:
		printHelp()

	if runImportPhase == False and runETLPhase == False and runCopyPhase == False:
		# If nothing is specified we run both stages
		runImportPhase = True
		runETLPhase = True

	if runOnlyFunction != None:
		if runOnlyFunction not in ("getSourceTableSchema", "onlyMain", "sqoop", "createImportTable", "getImportTableRowCount", "getTargetTableRowCount", "createTargetTable", "removeHiveLocks", "truncateTargetTable", "loadDataFromImportTable", "createStatistics", "getSourceTableRowCount", "mergeTable", "createHistoryTable", "createDeleteTable"):
			printHelp()

	# Initiate the logging functions with the correct level
	if loggingLevel == logging.DEBUG:
		logging.basicConfig(format='%(levelname)s %(funcName)s - %(message)s', level=loggingLevel)
	else:
		logging.basicConfig(format='%(levelname)s - %(message)s', level=loggingLevel)

	# Font created at http://patorjk.com/software/taag/#p=display&f=Big&t=DBImport%20-%20Import
	sys.stdout.write(u"\u001b[35m")  # Magenta
	sys.stdout.flush()
	print("")
	print(" _____  ____ _____                            _              _____                            _   ")
	print("|  __ \|  _ \_   _|                          | |            |_   _|                          | |  ")
	print("| |  | | |_) || |  _ __ ___  _ __   ___  _ __| |_   ______    | |  _ __ ___  _ __   ___  _ __| |_ ")
	print("| |  | |  _ < | | | '_ ` _ \| '_ \ / _ \| '__| __| |______|   | | | '_ ` _ \| '_ \ / _ \| '__| __|")
	print("| |__| | |_) || |_| | | | | | |_) | (_) | |  | |_            _| |_| | | | | | |_) | (_) | |  | |_ ")
	print("|_____/|____/_____|_| |_| |_| .__/ \___/|_|   \__|          |_____|_| |_| |_| .__/ \___/|_|   \__|")
	print("                            | |                                             | |                   ")
	print("                            |_|                                             |_|                   ")
	sys.stdout.write(u"\u001b[0m")  # Reset
	sys.stdout.flush()
	print("")
	print("Version: %s"%(constant.VERSION))
	print("")
	print("")
	
	# Initiate the master class for all import operations
	import_operation = import_operations.operation(Hive_DB, Hive_Table)
	etl_operation = etl_operations.operation()

	# Get the name of the different phases we are going to execute
	importPhase = import_operation.import_config.importPhase 
	copyPhase   = import_operation.import_config.copyPhase 
	etlPhase    = import_operation.import_config.etlPhase 
	importPhaseDescription = import_operation.import_config.importPhaseDescription 
	copyPhaseDescription   = import_operation.import_config.copyPhaseDescription 
	etlPhaseDescription    = import_operation.import_config.etlPhaseDescription 

	print("The following table will be imported")
	print("______________________________________________________________________________")
	print("")
	print("Import Type (OLD):        %s"%(import_operation.import_config.import_type))
	print("Import description (OLD): %s"%(import_operation.import_config.import_type_description))
	print("Import Phase:             %s"%(importPhaseDescription))
	print("Copy Phase:               %s"%(copyPhaseDescription))
	print("ETL Phase:                %s"%(etlPhaseDescription))
#	print("Export Phase:             %s"%("No Export"))
	print("Source hostname:          %s"%(import_operation.import_config.common_config.jdbc_hostname))
	print("Source database type:     %s"%(import_operation.import_config.common_config.jdbc_servertype))
	print("Source database:          %s"%(import_operation.import_config.common_config.jdbc_database))
	if import_operation.import_config.source_schema != "-":
		print("Source schema:            %s"%(import_operation.import_config.source_schema))
	print("Source table:             %s"%(import_operation.import_config.source_table))
	print("Hive database:            %s"%(import_operation.import_config.Hive_DB))
	print("Hive table:               %s"%(import_operation.import_config.Hive_Table))
	print("______________________________________________________________________________")
	print("")
	sys.stdout.flush()

	if ( runImportPhase == True and runETLPhase == False ) and runOnlyFunction == None:
		print(" _____________________ ")
		print("|                     |")
		print("| Import Phase only   |")
		print("|_____________________|")
		print("")
		print("")

	if ( runImportPhase == False and runETLPhase == True ) and runOnlyFunction == None:
		print(" __________________")
		print("|                  |")
		print("| ETL Phase only   |")
		print("|__________________|")
		print("")
		print("")

	if runOnlyFunction != None:
		print(" _______________________________________________________ ")
		print("|                                                       |")
		print("| This is not a full import as a function was specified |") 	
		print("|_______________________________________________________|")
		print("")
		print("")

		import_operation.setStageOnlyInMemory()

		# Check if the configured Hive database exists
		import_operation.checkHiveDB(Hive_DB.lower())
		

	if ignoreTime == False:
#		# Checking if we are allowed to use the configued JDBC connection at this time
		import_operation.checkTimeWindow()

	if import_operation.import_config.common_config.checkKerberosTicket() == False:
		logging.error("There is no valid Kerberos ticket available. Please create one before running this command")
		import_operation.remove_temporary_files()
		sys.exit(1)

	stage = import_operation.getStage()
	if resetStage == True:
		import_operation.setStage(0, force=True)
		stage = 0

	if stage > 0 and stage < 1000:
		# TODO: Remove this once everything is migrated to python version
		print(" ________________________________________________________ ")
		print("|                                                        |")
		print("| ERROR: Stage information incorrect. Did you run the    |") 	
		print("|        python version of DBImport last time?           |") 	
		print("|________________________________________________________|")
		print("")
		print("")
		import_operation.remove_temporary_files()
		sys.exit(1)

	if runImportPhase == True and runETLPhase == False and ( stage == 1049 or stage == 1149 ):
		print(" ______________________________________ ")
		print("|                                      |")
		print("| Import Phase is already completed.   |") 
		print("| To continue, run with option '-2'    |") 	
		print("|______________________________________|")

		import_operation.remove_temporary_files()
		sys.exit(0)

	# ******************************************
	# * IMPORT_PHASE_FULL 
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and runImportPhase == True:
		if stage >= 1000 and stage < 1049:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 1014: newStage = 1011 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")


		# Fetch the source table schema. This is mandatory for all imports
		if runOnlyFunction == None or runOnlyFunction == "getSourceTableSchema":
			import_operation.setStage(1010)
			if import_operation.getStage() == 1010: 
				import_operation.getSourceTableSchema()

		if runOnlyFunction == None: 
			import_operation.setStage(1011)
			if import_operation.getStage() == 1011: 
				import_operation.clearTableRowCount()

		if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount": 
			import_operation.setStage(1012)
			if import_operation.getStage() == 1012: 
				import_operation.getJDBCTableRowCount()
	
		if ( runOnlyFunction == None or runOnlyFunction == "sqoop" ) and skipSqoop == False:
			import_operation.setStage(1013)
			if import_operation.getStage() == 1013: 
				import_operation.runSqoop(False)

			import_operation.setStage(1014)
			if import_operation.getStage() == 1014: 
				import_operation.validateSqoopRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(1049)


	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_TRUNCATEINSERT
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_TRUNCATEINSERT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3053: newStage = 3050 
			if stage == 3060: newStage = 3054
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")


		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			import_operation.setStage(3050)
			if import_operation.getStage() == 3050: 
				import_operation.connectToHive()

			import_operation.setStage(3051)
			if import_operation.getStage() == 3051: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			import_operation.setStage(3052)
			if import_operation.getStage() == 3052: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			import_operation.setStage(3053)
			if import_operation.getStage() == 3053: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			import_operation.setStage(3054)
			if import_operation.getStage() == 3054: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			import_operation.setStage(3055)
			if import_operation.getStage() == 3055: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "truncateTargetTable":
			import_operation.setStage(3056)
			if import_operation.getStage() == 3056: 
				import_operation.connectToHive()
				import_operation.truncateTargetTable()
		
		if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
			import_operation.setStage(3057)
			if import_operation.getStage() == 3057: 
				import_operation.connectToHive()
				import_operation.loadDataFromImportToTargetTable()

			import_operation.setStage(3058)
			if import_operation.getStage() == 3058: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			import_operation.setStage(3059)
			if import_operation.getStage() == 3059: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			import_operation.setStage(3060)
			if import_operation.getStage() == 3060: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR 
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_INCR and runImportPhase == True:
		stage = import_operation.getStage()
		if stage >= 1100 and stage < 1149:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 1114: newStage = 1111 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		# Fetch the source table schema. This is mandatory for all imports
		if runOnlyFunction == None or runOnlyFunction == "getSourceTableSchema":
			import_operation.setStage(1110)
			if import_operation.getStage() == 1110: 
				import_operation.getSourceTableSchema()

		if runOnlyFunction == None: 
			import_operation.setStage(1111)
			if import_operation.getStage() == 1111: 
				import_operation.clearTableRowCount()

		if ( runOnlyFunction == None or runOnlyFunction == "sqoop" ) and skipSqoop == False:
			import_operation.setStage(1112)
			if import_operation.getStage() == 1112: 
				import_operation.saveIncrMinValue()
				import_operation.runSqoop(False)
				if import_operation.sqoopIncrNoNewRows == True: 
					import_operation.setStage(1149)

		if runOnlyFunction == None or runOnlyFunction == "getSourceTableRowCount": 
			import_operation.setStage(1113)
			if import_operation.getStage() == 1113: 
				import_operation.getJDBCTableRowCount()
	
		if runOnlyFunction == None:
			import_operation.setStage(1114)
			if import_operation.getStage() == 1114: 
				import_operation.validateSqoopRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(1149)

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_INSERT
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_INSERT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3153: newStage = 3150 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3160)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			import_operation.setStage(3150)
			if import_operation.getStage() == 3150: 
				import_operation.connectToHive()

			import_operation.setStage(3151)
			if import_operation.getStage() == 3151: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			import_operation.setStage(3152)
			if import_operation.getStage() == 3152: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			import_operation.setStage(3153)
			if import_operation.getStage() == 3153: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			import_operation.setStage(3154)
			if import_operation.getStage() == 3154: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			import_operation.setStage(3155)
			if import_operation.getStage() == 3155: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "loadDataFromImportTable":
			import_operation.setStage(3156)
			if import_operation.getStage() == 3156: 
				import_operation.connectToHive()
				import_operation.loadDataFromImportToTargetTable()

			import_operation.setStage(3157)
			if import_operation.getStage() == 3157: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			import_operation.setStage(3158)
			if import_operation.getStage() == 3158: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			import_operation.setStage(3159)
			if import_operation.getStage() == 3159: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			import_operation.setStage(3160)
			if import_operation.getStage() == 3160: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEHISTORYAUDIT
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3211: newStage = 3204 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			import_operation.setStage(3200)
			if import_operation.getStage() == 3200: 
				import_operation.connectToHive()

			import_operation.setStage(3201)
			if import_operation.getStage() == 3201: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			import_operation.setStage(3202)
			if import_operation.getStage() == 3202: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			import_operation.setStage(3203)
			if import_operation.getStage() == 3203: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			import_operation.setStage(3204)
			if import_operation.getStage() == 3204: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			import_operation.setStage(3205)
			if import_operation.getStage() == 3205: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.convertHiveTableToACID()
				import_operation.updateTargetTable()
				import_operation.addHiveMergeColumns()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
			import_operation.setStage(3206)
			if import_operation.getStage() == 3206: 
				import_operation.connectToHive()
				import_operation.createHistoryTable()
				import_operation.updateHistoryTable()

		if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
			import_operation.setStage(3207)
			if import_operation.getStage() == 3207: 
				import_operation.connectToHive()
				import_operation.createDeleteTable()
				import_operation.updateDeleteTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			import_operation.setStage(3208)
			if import_operation.getStage() == 3208: 
				import_operation.connectToHive()
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = import_operation.import_config.Hive_Import_Table, 
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
					historyDB = import_operation.import_config.Hive_History_DB, 
					historyTable = import_operation.import_config.Hive_History_Table, 
					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = True,
					sourceIsIncremental = False,
					sourceIsImportTable = True,
					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			import_operation.setStage(3209)
			if import_operation.getStage() == 3209: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			import_operation.setStage(3210)
			if import_operation.getStage() == 3210: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			import_operation.setStage(3211)
			if import_operation.getStage() == 3211: 
				import_operation.validateRowCount()

#		if runOnlyFunction == None:
#			import_operation.setStage(3211)
#			if import_operation.getStage() == 3211: 
#				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()


	# ******************************************
	# * IMPORT_PHASE_FULL & ETL_PHASE_MERGEONLY
	# ******************************************

	if importPhase == constant.IMPORT_PHASE_FULL and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1049:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			if stage == 3260: newStage = 3254 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		if runImportPhase == False and stage < 1049:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			import_operation.setStage(3250)
			if import_operation.getStage() == 3250: 
				import_operation.connectToHive()

			import_operation.setStage(3251)
			if import_operation.getStage() == 3251: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			import_operation.setStage(3252)
			if import_operation.getStage() == 3252: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			import_operation.setStage(3253)
			if import_operation.getStage() == 3253: 
				import_operation.validateRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			import_operation.setStage(3254)
			if import_operation.getStage() == 3254: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			import_operation.setStage(3255)
			if import_operation.getStage() == 3255: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.convertHiveTableToACID()
				import_operation.updateTargetTable()
				import_operation.addHiveMergeColumns()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createDeleteTable":
			import_operation.setStage(3256)
			if import_operation.getStage() == 3256: 
				import_operation.connectToHive()
				import_operation.createDeleteTable()
				import_operation.updateDeleteTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			import_operation.setStage(3257)
			if import_operation.getStage() == 3257: 
				import_operation.connectToHive()
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = import_operation.import_config.Hive_Import_Table, 
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
#					historyDB = import_operation.import_config.Hive_History_DB, 
#					historyTable = import_operation.import_config.Hive_History_Table, 
					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = False,
					sourceIsIncremental = False,
					sourceIsImportTable = True,
					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			import_operation.setStage(3258)
			if import_operation.getStage() == 3258: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			import_operation.setStage(3259)
			if import_operation.getStage() == 3259: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			import_operation.setStage(3260)
			if import_operation.getStage() == 3260: 
				import_operation.validateRowCount()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEONLY
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEONLY and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3309: newStage = 3304 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3310)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3300) == True: 
				import_operation.connectToHive()

			if import_operation.runStage(3301) == True: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3302) == True: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3303) == True: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3304) == True: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3305) == True: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3306) == True: 
				import_operation.connectToHive()
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = import_operation.import_config.Hive_Import_Table, 
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
#					historyDB = import_operation.import_config.Hive_History_DB, 
#					historyTable = import_operation.import_config.Hive_History_Table, 
#					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
#					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = False,
					sourceIsIncremental = True,
					sourceIsImportTable = True,
					softDelete = None,
#					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3307) == True: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3308) == True: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3309) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3310) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	# ******************************************
	# * IMPORT_PHASE_INCR & ETL_PHASE_MERGEHISTORYAUDIT
	# ******************************************
	
	if importPhase == constant.IMPORT_PHASE_INCR and etlPhase == constant.ETL_PHASE_MERGEHISTORYAUDIT and runETLPhase == True:
		stage = import_operation.getStage()
		if stage > 0 and stage != 1149:
			import_operation.saveRetryAttempt(stage)

			newStage = 0
			# TODO: Add correct restart points once incremental imports are working
			if stage == 3360: newStage = 3354 
			print(" ________________________________________________________ ")
			print("|                                                        |")
			print("| WARNING: The previous import failed and this execution |") 	
			print("|          is recovering from that failure.              |") 	
			print("| Last execution failed on stage %s                    |"%(stage)) 	
			if newStage != 0: 
				print("| Will restart from stage %s                           |"%(newStage)) 	
				import_operation.setStage(newStage, force=True)
			print("|________________________________________________________|")
			print("")
			print("")

		if runImportPhase == False and stage < 1149:
			logging.error("You are trying to execute a ETL Phase only import, but there is no information about a completed import phase")
			logging.error("Please run a import phase first and make sure it completes successfully")
			import_operation.remove_temporary_files()
			sys.exit(0)

		if runOnlyFunction == None:
			if import_operation.import_config.sqoop_last_rows == 0:
				# As we have passed the sqoop validation, we can assume that if sqoop havent loaded any rows, there is nothing to do in stage2
				import_operation.setStage(3361)

		if runOnlyFunction == None or runOnlyFunction == "createImportTable":
			if import_operation.runStage(3350) == True: 
				import_operation.connectToHive()

			if import_operation.runStage(3351) == True: 
				import_operation.connectToHive()
				import_operation.createExternalImportTable()
				import_operation.updateExternalImportTable()

		if runOnlyFunction == None or runOnlyFunction == "getImportTableRowCount":
			if import_operation.runStage(3352) == True: 
				import_operation.connectToHive()
				import_operation.getImportTableRowCount()

			if import_operation.runStage(3353) == True: 
				import_operation.validateIncrRowCount()

		if runOnlyFunction == None or runOnlyFunction == "removeHiveLocks":
			if import_operation.runStage(3354) == True: 
				import_operation.connectToHive()
				import_operation.removeHiveLocks()

		if runOnlyFunction == None or runOnlyFunction == "createTargetTable":
			if import_operation.runStage(3355) == True: 
				import_operation.connectToHive()
				import_operation.createTargetTable()
				import_operation.updateTargetTable()
				import_operation.updatePKonTargetTable()
				import_operation.updateFKonTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "createHistoryTable":
			if import_operation.runStage(3356) == True: 
				import_operation.connectToHive()
				import_operation.createHistoryTable()
				import_operation.updateHistoryTable()

		if runOnlyFunction == None or runOnlyFunction == "mergeTable":
			if import_operation.runStage(3357) == True: 
				import_operation.connectToHive()
				etl_operation.mergeHiveTables(
					sourceDB = import_operation.import_config.Hive_Import_DB, 
					sourceTable = import_operation.import_config.Hive_Import_Table, 
					targetDB = import_operation.import_config.Hive_DB, 
					targetTable = import_operation.import_config.Hive_Table, 
					historyDB = import_operation.import_config.Hive_History_DB, 
					historyTable = import_operation.import_config.Hive_History_Table, 
#					targetDeleteDB = import_operation.import_config.Hive_Delete_DB, 
#					targetDeleteTable = import_operation.import_config.Hive_Delete_Table, 
					createHistoryAudit = True,
					sourceIsIncremental = True,
					sourceIsImportTable = True,
					softDelete = None,
#					softDelete = import_operation.import_config.soft_delete_during_merge, 
					mergeTime = import_operation.import_config.sqoop_last_execution_timestamp,
					datalakeSource = import_operation.import_config.datalake_source,
					PKColumns = import_operation.import_config.getPKcolumns(PKforMerge=True),
					hiveMergeJavaHeap = import_operation.import_config.hive_merge_javaheap
				)

			if import_operation.runStage(3358) == True: 
				import_operation.updateStatisticsOnTargetTable()

		if runOnlyFunction == None or runOnlyFunction == "getTargetTableRowCount":
			if import_operation.runStage(3359) == True: 
				import_operation.connectToHive()
				import_operation.getTargetTableRowCount()

			if import_operation.runStage(3360) == True: 
				import_operation.validateRowCount()

		if runOnlyFunction == None:
			if import_operation.runStage(3361) == True: 
				import_operation.saveIncrPendingValues()

			import_operation.setStage(9999)

		if runOnlyFunction == None or runOnlyFunction == "createStatistics":
			import_operation.convertStageStatisticsToJSON()
			import_operation.saveStageStatistics()

	if import_operation.getStage() == 9999: 
		if runOnlyFunction == None:
			if runImportPhase == True and runETLPhase == False:
				print(" ___________________________________ ")
				print("|                                   |")
				print("| Import Phase completed successful |") 	
				print("|___________________________________|")
			elif runImportPhase == False and runETLPhase == True:
				print(" ________________________________ ")
				print("|                                |")
				print("| ETL Phase completed successful |") 	
				print("|________________________________|")
			else:
				print(" _____________________________ ")
				print("|                             |")
				print("| Import completed successful |") 	
				print("|_____________________________|")
			print("")

			if runETLPhase == True:
				# We can only clear the stage at the end of stage 2. 
				import_operation.clearStage()
#	else:
#		logging.error("This import tool only supports 'full' and 'full_direct' so far. Please use bash version for other imports")
#		import_operation.remove_temporary_files()
#		sys.exit(1)

	import_operation.remove_temporary_files()

if __name__ == "__main__":
	main(sys.argv[1:])

