#!/usr/bin/env python3
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
import getopt
import logging
from common import constants as constant
from DBImportConfig import common_config
from DBImportConfig import rest
from DBImportOperation import import_operations
from DBImportOperation import export_operations

def printHelp():
	print ("Options:")
	print ("  --clearImportStage Clear the Import stage. Requires [Hive Database] and [Hive Table] paramaters")
	print ("  --clearExportStage Clear the Export stage. Requires [Connection], [Schema] and [Table]")
	print ("  --testConnection   Connect to the [Connection] and verifies if we can connect successfully")
	print ("  --encryptCredentials")
	print ("                     Encrypt username and password for a Database Connection. ")
	print ("  --sendJSONstatistics")
	print ("                     Posts the JSON data in the 'json_to_rest' table to the configured REST endpoints")
	print ("  --repairIncrementalImport")
	print ("                     Repairs an incremental import by getting the max value for incremental column and set that")
	print ("                     as a starting point for the next import. Requires [Hive Database] and [Hive Table] paramaters")
	print ("  --repairAllIncrementalImports")
	print ("                     Repairs all incremental import that have an active stage.")
	print ("  --resetIncrementalImport")
	print ("                     Resets an incremental import. This will truncate the Target table and force the next import")
	print ("                     to start from the begining with a full import. Requires [Hive Database] and [Hive Table] paramaters")
	print ("  --repairIncrementalExport")
	print ("                     Tries to repair an incremental import by reading the max value for the incremental column from the ")
	print ("                     Target Table and use that as the max value for the next export. Requires [Connection], [Schema] and [Table]")
	print ("  --resetIncrementalExport")
	print ("                     Resets an incremental export. This will truncate the Target table and force the next export")
	print ("                     to start from the begining with a full export. Requires [Connection], [Schema] and [Table]")
	print ("  --dropExportTable")
	print ("                     Drops an Export table and forces an incremental import to start from a full export.")
	print ("                     Requires [Connection], [Schema] and [Table]")
	print ("")
	print ("  --addImportTable")
	print ("                     Connects to the source database and reads all tables and view, or a selection if [Schema] or [Table]")
	print ("                     is specified and insert those tables/views to import_tables. Requires [Hive Database] and [Connection].")
	print ("                     [Schema] and [Table] supports wildcard here ")
	print ("  --addSchemaToTable If this is specified, the schema on the source database is added to the Hive Table name")
	print ("")
	print ("  --addExportTable")
	print ("                     Add export definitions for all tables in Hive, or just specific tables if filters for ")
	print ("                     [Hive Database] or [Hive Table] was specfied. Requires [Connection] and [Schema].")
	print ("                     [Hive Database] and [Hive Table] supports wildcard here ")
	print ("  --addDBToTable     If this is specified, the Hive database is added to the Target Table name")
	print ("")
	print ("  --counterStart=[Start]")
	print ("  --addCounterToTable If this is specified, a counter starting from [Start] is added to begining of the Hive/Target Table name")
	print ("  --addCustomText=[Custom Text]")
	print ("                     Add the custom text to the Hive Table or to the Target Table for imports and exports")
	print ("")
	print ("  -h [Hive Database], --hiveDB=[Hive Database]")
	print ("                     Hive database")
	print ("")
	print ("  -t [Hive Table], --hiveTable=[Hive Table]")
	print ("                     Hive table")
	print ("")
	print ("  -a [Connection], --dbAlias=[Connection]")
	print ("                     The alias of the JDBC connection")
	print ("")
	print ("  -S [Schema], --schema=[Schema]")
	print ("                     Schema name of the table to export")
	print ("")
	print ("  -T [Table], --table=[Table]")
	print ("                     Table to export")
	print ("")
	print ("  -y, --yes          Auto answer 'Yes' to all questions")
	print ("  --help             Show this help message and exit")
	print ("  -v, --debug        Turn on extensive debug output. This will print passwords in cleartext, so use with caution")
	sys.exit(1)
	
def main(argv):

	try:
		opts, args = getopt.getopt(argv, "yvh:t:a:S:T:", ["yes", "help", "resetIncrementalExport", "repairAllIncrementalImports", "repairIncrementalImport", "resetIncrementalImport", "sendJSONstatistics", "encryptCredentials", "clearImportStage", "Hive_DB=", "hiveDB=", "Hive_Table=", "hiveTable=", "dbAlias=", "schema=", "table=", "debug", "repairIncrementalExport", "clearExportStage", "dropExportTable", "addImportTable", "addSchemaToTable", "addExportTable", "addCounterToTable", "addDBToTable", "counterStart=", "addCustomText=", "testConnection"])
	except getopt.GetoptError:
		printHelp()

	Hive_DB = None
	Hive_Table = None
	operation = None
	loggingLevel = logging.INFO
	connectionAlias = None
	jdbcSchema = None
	jdbcTable = None
	addSchemaToTable = False
	addCounterToTable = False
	addDBToTable = False
	addCustomText = None
	counterStart = None
	autoYesAnswer = False

	if  len(opts) == 0:
		printHelp()

	for opt, arg in opts:
		if opt == "--help":
			printHelp()
		elif opt in ("-y", "--yes"):
			autoYesAnswer = True
		elif opt in ("-v", "--debug"):
			loggingLevel = logging.DEBUG
		elif opt in ("-h", "--hiveDB", "--Hive_DB"):
			Hive_DB = arg
		elif opt in ("-t", "--hiveTable", "--Hive_Table"):
			Hive_Table = arg
		elif opt in ("-a", "--dbAlias"):
			connectionAlias = arg
		elif opt in ("-S", "--schema"):
			jdbcSchema = arg
		elif opt in ("-T", "--table"):
			jdbcTable = arg
		elif opt == "--addSchemaToTable":
			addSchemaToTable = True
		elif opt == "--addCounterToTable":
			addCounterToTable = True
		elif opt == "--addDBToTable":
			addDBToTable = True
		elif opt == "--addCustomText":
			addCustomText = arg
		elif opt == "--counterStart":
			counterStart = str(arg)
		elif opt == "--clearImportStage":
			operation = "clearImportStage"
		elif opt == "--clearExportStage":
			operation = "clearExportStage"
		elif opt == "--encryptCredentials":
			operation = "encryptCredentials"
		elif opt == "--sendJSONstatistics":
			operation = "sendJSONstatistics"
		elif opt == "--repairIncrementalImport":
			operation = "repairIncrementalImport"
		elif opt == "--repairAllIncrementalImports":
			operation = "repairAllIncrementalImports"
		elif opt == "--resetIncrementalImport":
			operation = "resetIncrementalImport"
		elif opt == "--resetIncrementalExport":
			operation = "resetIncrementalExport"
		elif opt == "--repairIncrementalExport":
			operation = "repairIncrementalExport"
		elif opt == "--dropExportTable":
			operation = "dropExportTable"
		elif opt == "--addImportTable":
			operation = "addImportTable"
		elif opt == "--addExportTable":
			operation = "addExportTable"
		elif opt == "--testConnection":
			operation = "testConnection"


	if operation == None:
		printHelp()

	if operation == "clearImportStage" and (Hive_DB == None or Hive_Table == None):
		printHelp()

	if operation == "repairIncrementalImport" and (Hive_DB == None or Hive_Table == None):
		printHelp()

	if operation == "resetIncrementalImport" and (Hive_DB == None or Hive_Table == None):
		printHelp()

	if operation == "clearExportStage" and (connectionAlias == None or jdbcSchema == None or jdbcTable == None):
		printHelp()

	if operation == "resetIncrementalExport" and (connectionAlias == None or jdbcSchema == None or jdbcTable == None):
		printHelp()

	if operation == "repairIncrementalExport" and (connectionAlias == None or jdbcSchema == None or jdbcTable == None):
		printHelp()

	if operation == "dropExportTable" and (connectionAlias == None or jdbcSchema == None or jdbcTable == None):
		printHelp()

	if operation == "addImportTable" and (Hive_DB == None or connectionAlias == None):
		printHelp()

	if operation == "addExportTable" and (connectionAlias == None or jdbcSchema == None):
		printHelp()

	if operation == "testConnection" and connectionAlias == None:
		printHelp()
	# Font created at http://patorjk.com/software/taag/#p=display&f=Big&t=DBImport%20-%20setup
	sys.stdout.write(u"\u001b[35m")  # Magenta
	sys.stdout.flush()
	print("")
	print(" _____  ____ _____                            _              __  __                               ")
	print("|  __ \|  _ \_   _|                          | |            |  \/  |                              ")
	print("| |  | | |_) || |  _ __ ___  _ __   ___  _ __| |_   ______  | \  / | __ _ _ __   __ _  __ _  ___  ")
	print("| |  | |  _ < | | | '_ ` _ \| '_ \ / _ \| '__| __| |______| | |\/| |/ _` | '_ \ / _` |/ _` |/ _ \ ")
	print("| |__| | |_) || |_| | | | | | |_) | (_) | |  | |_           | |  | | (_| | | | | (_| | (_| |  __/ ")
	print("|_____/|____/_____|_| |_| |_| .__/ \___/|_|   \__|          |_|  |_|\__,_|_| |_|\__,_|\__, |\___| ")
	print("                            | |                                                        __/ |      ")
	print("                            |_|                                                       |___/       ")
	sys.stdout.write(u"\u001b[0m")  # Reset
	sys.stdout.flush()
	print("")
	print("Version: %s"%(constant.VERSION))
	print("")
	print("")

	# Initiate the logging functions with the correct level
	if loggingLevel == logging.DEBUG:
		logging.basicConfig(format='%(levelname)s %(funcName)s - %(message)s', level=loggingLevel)
	else:
		logging.basicConfig(format='%(levelname)s - %(message)s', level=loggingLevel)

	if operation == "clearImportStage":
		import_operation = import_operations.operation(Hive_DB, Hive_Table)
		import_operation.clearStage()
		logging.info("Stage information cleared for %s.%s"%(Hive_DB, Hive_Table))

		import_operation.remove_temporary_files()

	if operation == "encryptCredentials":
		print("This function will encrypt a username and password for the specified Database Connection. Any previous username/password will be overwritten")
		print("There is no undo function for this, so if you want to cancel, please press Ctrl-C")
		connectionAlias = input("DataBase Connection (dbalias): ")

		commonConfig = common_config.config()
		if commonConfig.checkConnectionAlias(connectionAlias) == False:
			logging.error("The specified database connection does not exist.")
			sys.exit(1)

		username = input("Username: ")
		password = input("Password: ")
		commonConfig.encryptUserPassword(connectionAlias, username, password)
		commonConfig.remove_temporary_files()

	if operation == "sendJSONstatistics":
		rest.postSQLDataToREST()

	if operation == "repairAllIncrementalImports":
		print("This command will search for incremental tables that have an entry in 'import_stage'. If the entry exists,")
		print("it will fetch the max value from the hive table and update the MySQL database. This value will then be used")
		print("used as the starting point for the next sqoop import.")
		print("")
		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			import_operation = import_operations.operation()
			import_operation.repairAllIncrementalImports()
			import_operation.remove_temporary_files()


	if operation == "repairIncrementalImport":
		print("This command will try to repair an incremental import that have come out-of-sync between data in the source table")
		print("and the hive table. The tool will connect to the hive database and read the max value for the column")
		print("that is used for the incremental loads. This value will then be used as the starting point for the next sqoop import")
		print("")
		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			import_operation = import_operations.operation(Hive_DB, Hive_Table)
			import_operation.resetIncrMaxValue()
			import_operation.remove_temporary_files()

	if operation == "resetIncrementalImport":
		print("This command will truncate the Target Table and force the next import to be a full import.")
		print("")
		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			import_operation = import_operations.operation(Hive_DB, Hive_Table)
			import_operation.resetIncrMinMaxValues(maxValue=None)
			import_operation.truncateTargetTable()
			import_operation.remove_temporary_files()

	if operation == "resetIncrementalExport":
		print("This command will truncate the Target Table and force the next export to be a full export.")
		print("")
		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			export_operation = export_operations.operation(connectionAlias=connectionAlias, targetSchema=jdbcSchema,targetTable=jdbcTable)
			export_operation.truncateJDBCTable()
			export_operation.resetIncrMinMaxValues(maxValue=None)
			export_operation.clearStage()
			export_operation.remove_temporary_files()

	if operation == "repairIncrementalExport":
		print ("This command will repair an incremental import by reading the max value for the incremental column from the ")
		print ("Target Table and use that as the max value for the next export.")
		print("")

		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			export_operation = export_operations.operation(connectionAlias=connectionAlias, targetSchema=jdbcSchema,targetTable=jdbcTable)
			export_operation.resetMaxValueFromTarget()
			export_operation.remove_temporary_files()

	if operation == "dropExportTable":
		print("This command will drop the Target Table and if it's an incremental export, force the next export to be a full export.")
		print("")

		if autoYesAnswer == False:
			answer = input("Are you sure you want to do this? (y/N): ")
		else:
			answer = "y"

		if answer.lower() == "y":
			export_operation = export_operations.operation(connectionAlias=connectionAlias, targetSchema=jdbcSchema,targetTable=jdbcTable)
			export_operation.dropJDBCTable()
			export_operation.resetIncrMinMaxValues(maxValue=None)
			export_operation.clearStage()
			export_operation.remove_temporary_files()

	if operation == "clearExportStage":
		export_operation = export_operations.operation(connectionAlias=connectionAlias, targetSchema=jdbcSchema,targetTable=jdbcTable)
		export_operation.clearStage()
		logging.info("Stage information cleared")

		export_operation.remove_temporary_files()

	if operation == "addImportTable":
		import_operation = import_operations.operation()
		import_operation.discoverAndAddTablesFromSource(
			dbalias=connectionAlias, 
			hiveDB=Hive_DB, 
			schemaFilter=jdbcSchema, 
			tableFilter=jdbcTable,
			addSchemaToTable=addSchemaToTable,
			addCustomText=addCustomText,
			addCounterToTable=addCounterToTable,
			counterStart=counterStart)
		
	if operation == "addExportTable":
		export_operation = export_operations.operation()
		export_operation.discoverAndAddTablesFromHive(
			dbFilter=Hive_DB, 
			tableFilter=Hive_Table,
			dbalias=connectionAlias, 
			schema=jdbcSchema, 
			addDBToTable=addDBToTable,
			addCustomText=addCustomText,
			addCounterToTable=addCounterToTable,
			counterStart=counterStart)
		
	if operation == "testConnection":
		commonConfig = common_config.config()
		if commonConfig.checkConnectionAlias(connectionAlias) == False:
			logging.error("The specified database connection does not exist.")
			sys.exit(1)
		commonConfig.lookupConnectionAlias(connectionAlias)
		commonConfig.connectToJDBC()
		print("Connected successfully")


if __name__ == "__main__":
	main(sys.argv[1:])
