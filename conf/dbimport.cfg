[Database]
mysql_hostname = l4326pp.sss.se.scania.com
mysql_port = 3306
mysql_database = DBImport
mysql_username = sqoop
mysql_password = fng4f8hGjhsdppwasb!sdg

[REST_statistics]
post_column_data = false
post_import_data = false
timeout = 5
# rest_endpoint = http://prodhadoop.scania.com:5001/dbimport
rest_endpoint = http://l4584p.sss.se.scania.com:5002/dbimport

[Import]
max_sql_sessions = 32
default_sql_sessions = 12

[Export]
max_sql_sessions = 32
default_sql_sessions = 2

[Kerberos]
principal=boszkk@GLOBAL.SCD.SCANIA.COM
# To avoid handling kinit from OS, set the following system environment variable to the keytab file that contains the
# principal above
# export KRB5_CLIENT_KTNAME=<KEYTAB FILE> 

[HDFS]
hdfs_address = hdfs://prodhadoop

# The HDFS blocksize in bytes. Can usually be found in /etc/hadoop/conf/hdfs-site.xml (search for dfs.blocksize)
hdfs_blocksize = 134217728

[Hive]
# metastore is a comma separated list of all Hive WebHCat servers with the format <HTTP/HTTPS>://<SERVERNAME>:<PORT>
metastore = http://l4327pp.sss.se.scania.com:50111, http://l4330pp.sss.se.scania.com:50111

# MySQL connection details
metastore_hostname = l4326pp.sss.se.scania.com
metastore_port = 3306
metastore_database = hive_metastore
metastore_username = sqoop
metastore_password = fng4f8hGjhsdppwasb!sdg

# If additional Hive messages should be printed
print_hive_message = false

# Run a test query against a predefined table to verify that Hive works before starting to run queries against it.
test_hive_execution = false

# Connection details to Hive LLAP
hostname = l4326pp.sss.se.scania.com
port = 10500
kerberos_service_name = hive

min_buckets = 8
max_buckets = 1024

[Sqoop]
yarnqueue = DataLoad

[Credentials]
# You need a private/public key in able to encrypt and decrypt the username and password for the jdbc connections
# To generate such a pair, please use the following command and then point out the path to the keys
# If the path dont start with a /, the DBIMPORT_HOME will be used as a starting point
# openssl genrsa -out dbimport_private_key.pem 8192
# openssl rsa -in dbimport_private_key.pem -out dbimport_public_key.pem -outform PEM -pubout

private_key = /localhome/boszkk/dbimport_private_key.pem 
public_key = /localhome/boszkk/dbimport_public_key.pem 

[WebAdmin]
use_ssl = true
cert_file = /localhome/boszkk/airflow_wildcard.sss.se.scania.com.cert.pem
key_file = /localhome/boszkk/airflow_wildcard.sss.se.scania.com.key.pem
port = 2443
secret_key = ChangeMe!
# authenticate_type can be LDAP or SQLITE
authenticate_type = LDAP
ldap_server = ldap://ldapse01.scania.com:389
ldap_uid_field = sAMAccountName
ldap_bind_user = CN=SERVICEHADOOP,OU=Service Accounts,DC=global,DC=scd,DC=scania,DC=com
ldap_bind_password = zb7!XzUMb64PxZNJrvhMn8
ldap_base_dn = DC=global,DC=scd,DC=scania,DC=com

