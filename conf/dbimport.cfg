[Database]
mysql_hostname = localhost
mysql_port = 3306
mysql_database = DBImport
mysql_username = dbimport
mysql_password = dbimport

[REST_calls]
# This setting is not in use yet
post_column_data = false
column_data_endpoint = "https://localhost:8080/test"

[Import]
max_sql_sessions = 32
default_sql_sessions = 12

[Kerberos]
# This setting is not in use yet
keytab=keytab.file
principal=user@REALM

[HDFS]
hdfs_address = hdfs://hadoopCluster

[Hive]
# This setting is not in use yet
# metastore is a comma separated list of all Hive WebHCat servers with the format <HTTP/HTTPS>://<SERVERNAME>:<PORT>
metastore = http://server1.localdomain:50111, http://server2.localdomaon:50111

# MySQL connection details
metastore_hostname = localhost
metastore_port = 3306
metastore_database = hive_metastore
metastore_username = dbimport
metastore_password = dbimport

# Run a test query against a predefined table to verify that Hive works before starting to run queries against it.
test_hive_execution = true

# If additional Hive messages should be printed
print_hive_message = false

# Connection details to Hive LLAP
hostname = hiveserver.localdomain
port = 10500
kerberos_service_name = hive

[Sqoop]
yarnqueue = default

[Credentials]
# You need a private/public key in able to encrypt and decrypt the username and password for the jdbc connections
# To generate such a pair, please use the following command and then point out the path to the keys
# If the path dont start with a /, the DBIMPORT_HOME will be used as a starting point
# openssl genrsa -out dbimport_private_key.pem 8192
# openssl rsa -in dbimport_private_key.pem -out dbimport_public_key.pem -outform PEM -pubout

private_key = conf/dbimport_private_key.pem 
public_key = conf/dbimport_public_key.pem 

